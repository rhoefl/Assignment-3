import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, log_loss
from sklearn.linear_model import SGDClassifier

cancer = load_breast_cancer()
X = cancer.data
y = cancer.target

print("breast cancer dataset loaded successfully")
print(f"shape of X: {X.shape}, shape of y: {y.shape}")

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=0, stratify=y
)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

clf = SGDClassifier(loss="log_loss", penalty=None, random_state=0)
clf.partial_fit(X_train[:1], y_train[:1], classes=np.array([0, 1]))

epochs = 200
train_losses, train_accs = [], []

for _ in range(epochs):
    clf.partial_fit(X_train, y_train)
    p_train = clf.predict_proba(X_train)
    train_losses.append(log_loss(y_train, p_train))
    train_accs.append(accuracy_score(y_train, clf.predict(X_train)))

y_pred = clf.predict(X_test)

acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred, zero_division=0)
rec = recall_score(y_test, y_pred, zero_division=0)
f1 = f1_score(y_test, y_pred, zero_division=0)
cm = confusion_matrix(y_test, y_pred)

print("(a) no weight penalty")
print(f"accuracy : {acc:.4f}")
print(f"precision: {prec:.4f}")
print(f"recall   : {rec:.4f}")
print(f"f1 score : {f1:.4f}")

plt.figure(figsize=(6,4))
plt.plot(train_losses)
plt.title("training log loss vs iterations (no penalty)")
plt.xlabel("iteration")
plt.ylabel("log loss")
plt.grid(True)
plt.show()

plt.figure(figsize=(6,4))
plt.plot(train_accs)
plt.title("training accuracy vs iterations (no penalty)")
plt.xlabel("iteration")
plt.ylabel("accuracy")
plt.grid(True)
plt.show()

plt.figure(figsize=(4,4))
sns.heatmap(cm, annot=True, fmt="d", cbar=False)
plt.title("confusion matrix (no penalty)")
plt.xlabel("predicted")
plt.ylabel("actual")
plt.show()

clf_l2 = SGDClassifier(loss="log_loss", penalty="l2", alpha=0.001, random_state=0)
clf_l2.partial_fit(X_train[:1], y_train[:1], classes=np.array([0, 1]))

train_losses2, train_accs2 = [], []

for _ in range(epochs):
    clf_l2.partial_fit(X_train, y_train)
    p_train = clf_l2.predict_proba(X_train)
    train_losses2.append(log_loss(y_train, p_train))
    train_accs2.append(accuracy_score(y_train, clf_l2.predict(X_train)))

y_pred2 = clf_l2.predict(X_test)

acc2 = accuracy_score(y_test, y_pred2)
prec2 = precision_score(y_test, y_pred2, zero_division=0)
rec2 = recall_score(y_test, y_pred2, zero_division=0)
f12 = f1_score(y_test, y_pred2, zero_division=0)
cm2 = confusion_matrix(y_test, y_pred2)

print("\n(b) with l2 weight penalty")
print(f"accuracy : {acc2:.4f}")
print(f"precision: {prec2:.4f}")
print(f"recall   : {rec2:.4f}")
print(f"f1 score : {f12:.4f}")

plt.figure(figsize=(6,4))
plt.plot(train_losses2)
plt.title("training log loss vs iterations (with l2 penalty)")
plt.xlabel("iteration")
plt.ylabel("log loss")
plt.grid(True)
plt.show()

plt.figure(figsize=(6,4))
plt.plot(train_accs2)
plt.title("training accuracy vs iterations (with l2 penalty)")
plt.xlabel("iteration")
plt.ylabel("accuracy")
plt.grid(True)
plt.show()

plt.figure(figsize=(4,4))
sns.heatmap(cm2, annot=True, fmt="d", cbar=False)
plt.title("confusion matrix (with l2 penalty)")
plt.xlabel("predicted")
plt.ylabel("actual")
plt.show()

print("\nsummary comparison")
print(f"no penalty: accuracy={acc:.4f}, f1={f1:.4f}")
print(f"l2 penalty: accuracy={acc2:.4f}, f1={f12:.4f}")
